# This is a basic workflow to help you get started with Actions

name: Update Database

concurrency: 
  group: database-build


# Controls when the action will run. 
on:
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron:  '15 10 * * *'    

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # Add "id-token" with the intended permissions.
    permissions:
      contents: 'write'
      id-token: 'write'  
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4
      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
            workload_identity_provider: '${{ secrets.WORKLOAD_IDENTITY_PROVIDER }}'
            service_account: '${{ secrets.SERVICE_ACCOUNT }}'
      - name: Set up Cloud Run
        uses: google-github-actions/setup-gcloud@v2
      - name: set longer cloud build timeout
        run: |
          gcloud config set builds/timeout 1800
          gcloud config get builds/timeout
      - name: dependencies
        run: |
          pip install sqlite-utils
          pip install https://github.com/fgregg/datasette/archive/refs/heads/no_limit_csv_publish.zip
      - name: get databases
        run: |
          wget https://github.com/fgregg/cmap-legistar/releases/download/nightly/cmap.db.zip
          unzip cmap.db.zip
          rm cmap.db.zip
      - name: Install Datasette plugins
        run: |
          datasette install datasette-auth-passwords datasette-auth-tokens
      - name: Deploy to Cloudrun
        run: |
          gcloud config set run/region us-central1
          gcloud config set project puddle-datamade
          datasette publish cloudrun *.db \
            --memory 2Gi \
            --cpu 1 \
            --max-instances=2 \
            --service puddle \
            --extra-options="--crossdb --setting sql_time_limit_ms 100000 --cors --setting facet_time_limit_ms 500 --setting allow_facet off --setting trace_debug 1" \
            -m metadata.yml \
            --install=datasette-atom \
            --install=datasette-rure \
            --install=pysqlite3-binary \
            --install=datasette-hashed-urls \
            --install=datasette-block-robots \
            --install=datasette-pretty-traces \
            --install datasette-datatable \
            --version-note=$GITHUB_RUN_NUMBER
      - name: keepalive
        uses: gautamkrishnar/keepalive-workflow@1.1.0    